This file will guide you to use our code to replicate the results of the paper.

We have performed all of our experiments using python version 3.6.5. Hence, we request the user to use this python version while using our package. 
If you are having problem upgrading python version, you can install anaconda from here: https://docs.anaconda.com/anaconda/install/linux/. Follow the steps carefully while you do so.
 

This folder contains the following:

Datasets/	  		-- This folder contains the datasets that we have used for the experiments

Output/		  		-- This folder contains the ouput files generated by the scripts 

Script4TestCases/	  	-- This folder contains necessary scripts to run the test cases

TestCases/	 	 	-- This folder contains all the 90 test cases that we have used for the experiments

MainFiles/			-- This folder contains the implementation of adaptive random testing approach described in the paper


Script_ranTest_analysis_all.py  -- Script to run all the test cases to get the results of adaptive random testing (RQs 1 and 2)

Script_ranTest_short.py		-- Script to run few test cases from all the test cases 


##Running experiments of the paper

The next step is to run our experiments. If you want to replicate the results of the adaptive random testing approach on 90 test cases run the following command:

$ python Script_ranTest_analysis_all.py

When running the script it will ask you for two inputs : 1)MAX_SAMPLES limit and 2)No of times test cases to run. We have done our experiments by setting MAX_SAMPLES to 900 (as ART already have INI_SAMPLES set to 100) and run each test cases at least 10 times. We suggest you to do the same as each of our technique involves some sort of randomness.

##Running shorter versions of the experiments

All the experiments for RQs 1 and 2 take a significant amount of time to run. Hence, if you do not wish to run the experiments for such long periods of time, we have created scripts for functional testing of our approach.

To get the results of the functional testing for adaptive random testing approaches, run the following command on the current directory 


$ python Script_ranTest_short.py
 

The scripts will generate some intermediate files and datasets. In the end the outputs will be stored in the Output folder. The Output file for each algorithm contains the output averaging over all the runs of each test case. For example, kNN*OutputFile contains the result of all the test cases built using kNN algorithm. Execution times or failure attempts for each test case have been computed by averaging over all the runs.
While running LightGbm algorithm some deprecation warnings might occur. As ART does not find non-monotonicity in LightGbm, we do not include all the LightGbm test cases here. However, in the short script a test case from LightGbm is added. You might see some convergence problem with some ML algorithms.
This is expected.

Our adaptive random testing approach involves randomness. We try to minimize this by running all the test cases 10 times. Even after that it might happen that you encounter a bit inconsistencies with the results mentioned in the paper.

All the execution times written in output files are in seconds.





