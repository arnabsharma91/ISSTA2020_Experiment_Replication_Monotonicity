This file will guide you to use our code to replicate the results of the paper.
 

This folder contains the following:

Datasets/	  		-- This folder contains the datasets that we have used for the experiments

Output/		  		-- This folder contains the ouput files generated by the scripts 

Script4TestCases/	  	-- This folder contains necessary scripts to run the test cases

TestCases/	 	 	-- This folder contains all the 90 test cases that we have used for the experiments

MainFiles/			-- This folder contains the implementation of the property-based testing approach described in the paper


Script_propTest_analysis_all.py  -- Script to run all the test cases to get the results of property-based testing (refer to RQ 1 where we compare PBT with ART and VBT)

Script_propTest_short.py	 -- Script to run few test cases from all the test cases 


##Running experiments of the paper

The next step is to run our experiments. If you want to replicate the results of the property based testing approach on 90 test cases run the following command:

$ python Script_propTest_analysis_all.py

When running the script it will ask you for two inputs : 1)MAX_SAMPLES limit and 2)No of times test cases to run. We have done our experiments by setting MAX_SAMPLES to 1000 and run each test cases at least 10 times. We suggest you to do the same as each of our technique involves some sort of randomness.


##Running shorter versions of the experiments

All the experiments for RQ 1 take a significant amount of time to run. Hence, if you do not wish to run the experiments for such long periods of time, we have created scripts for functional testing of our approach.

To get the results of the functional testing for property-based testing approaches, run the following command on the current directory 


$ python Script_propTest_short.py
 

The scripts will generate some intermediate files and datasets. When the Property based testing tool shows an 'assertion error' that means it found a counter example violating monotonicity.
In the end, the outputs will be stored in the Output folder. If PBT does not find any counter example, the output file also does not contain any. The Output file for each algorithm contains the output averaging over all the runs of each test case. For example, kNN*OutputFile contains the result of all the test cases built using kNN algorithm. Execution time for each test case has been computed by averaging over all the runs.
While running 
LightGbm algorithm some deprecation warnings might occur. As PBT does not find non-monotonicity in LightGbm, we do not include all the LightGbm test cases here. However, in the short script a test case from LightGbm is added. You might see some convergence problems with some ML algorithms.
This is expected.

We have set the parameters of the quickcheck in a specific way to get the desired result. To answer the RQ1 we have set quickchek to generate only the single counter-example it could find. 
The test cases were run 10 times to deal with the problem of randomness.

All the execution times written in output files are in seconds.





