This file will guide you to use our code to replicate the results of the paper.

This folder contains the following:

Datasets/	  		-- This folder contains the datasets that we have used for the experiments

Output/		  		-- This folder contains the ouput files generated by the scripts 

Script4TestCases/	  	-- This folder contains necessary scripts to run the test cases

TestCases/	 	 	-- This folder contains all the 90 test cases that we have used for the experiments

MainFiles/			-- This folder contains the implementation of property based testing approach described in the paper


Script_propTest_analysis_all.py  -- Script to run all the test cases to get the results of property based testing (refer to RQ 2 where we compare PBT with ART and VBT)

Script_propTest_short.py	 -- Script to run few test cases from all the test cases 


##Running experiments of the paper

The next step is to run our experiments. If you want to replicate the results of the property based testing approach on 90 test cases run the following command:

$ python Script_propTest_analysis_all.py


##Running shorter versions of the experiments

All the experiments for RQ 2 take a significant amount of time to run. Hence, if you do not wish to run the experiments for such long periods of time, we have created scripts for functional testing of our approach.

To get the results of the functional testing for property based testing approaches, run the following command on the current directory 


$ python Script_propTest_short.py
 

The scripts will generate some intermediate files and datasets. When the Property based testing tool shows an 'assertion error' that means it found a counter example violating monotonicity
In the end the outputs will be stored in the Output folder. The Output file for each algorithm contains the output averaging over all the runs of each test case. For example, kNN*OutputFile contains the result of all the test cases built using kNN algorithm. Execution times or failure attempts for each test case have been computed by averaging over all the runs.
While running 
LightGbm algorithm some deprecation warnings might occur. As PBT does not find non-monotonicity in LightGbm, we do not include all the LightGbm test cases here. However, in the short script a test case from LightGbm is added. You might see some convergence problem with some ML algorithms.
This is expected.

We have set the parameters of the quickcheck in a specific way to get the desired result. To answer the RQ2 we have set quickchek to generate the trying examples before finding a valid counter example. 
The test cases were run 10 times to deal with the problem of randomness.

All the execution times written in output files are in seconds.





